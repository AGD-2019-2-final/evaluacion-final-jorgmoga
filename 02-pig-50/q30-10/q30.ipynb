{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bigdata extension is already loaded. To reload it, use:\n",
      "  %reload_ext bigdata\n",
      "Deleted data.csv\n",
      "Found 1 items\n",
      "-rw-r--r--   1 root supergroup        632 2020-03-07 00:01 data.csv\n"
     ]
    }
   ],
   "source": [
    "%load_ext bigdata\n",
    "%pig_start\n",
    "%timeout 300\n",
    "!hadoop fs -rm data.csv\n",
    "!hadoop fs -put data.csv\n",
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,Vivian,Hamilton,1971-07-08,green,1\n",
      "2,Karen,Holcomb,1974-05-23,green,4\n",
      "3,Cody,Garrett,1973-04-22,orange,1\n",
      "4,Roth,Fry,1975-01-29,black,1\n",
      "5,Zoe,Conway,1974-07-03,blue,2\n",
      "6,Gretchen,Kinney,1974-10-18,viole,1\n",
      "7,Driscoll,Klein,1970-10-05,blue,5\n",
      "8,Karyn,Diaz,1969-02-24,red,1\n",
      "9,Merritt,Guy,1974-10-17,indigo,4\n",
      "10,Kylan,Sexton,1975-02-28,black,4\n",
      "11,Jordan,Estes,1969-12-07,indigo,4\n",
      "12,Hope,Coffey,1973-12-24,green,5\n",
      "13,Vivian,Crane,1970-08-27,gray,5\n",
      "14,Clio,Noel,1972-12-12,red,5\n",
      "15,Hope,Silva,1970-07-01,blue,5\n",
      "16,Ayanna,Jarvis,1974-02-11,orange,5\n",
      "17,Chanda,Boyer,1973-04-01,green,4\n",
      "18,Chadwick,Knight,1973-04-29,yellow,1"
     ]
    }
   ],
   "source": [
    "!hadoop fs -cat data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " u = LOAD 'data.csv' USING PigStorage(',') \n",
      "    AS (id:int, \n",
      "        firstname:CHARARRAY, \n",
      "        surname:CHARARRAY, \n",
      "        birthday:CHARARRAY, \n",
      "        color:CHARARRAY, \n",
      "        quantity:INT);\n",
      " DUMP u;\n",
      "2020-03-07 00:01:17,481 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-07 00:01:17,766 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-03-07 00:01:17,771 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2020-03-07 00:01:17,787 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2020-03-07 00:01:18,663 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2020-03-07 00:01:18,673 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-07 00:01:18,699 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-03-07 00:01:18,814 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-03-07 00:01:18,856 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-07 00:01:18,957 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-03-07 00:01:19,127 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1583528081834_0086\n",
      "2020-03-07 00:01:19,292 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-03-07 00:01:19,461 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1583528081834_0086\n",
      "2020-03-07 00:01:19,509 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://d360b6ea3f8c:8088/proxy/application_1583528081834_0086/\n",
      "2020-03-07 00:01:39,793 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-07 00:01:39,804 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-07 00:01:40,078 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-07 00:01:40,101 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-07 00:01:40,153 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-03-07 00:01:40,157 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-07 00:01:40,166 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-07 00:01:40,303 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-07 00:01:40,316 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-07 00:01:40,403 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-07 00:01:40,416 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-07 00:01:40,474 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-07 00:01:40,481 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-07 00:01:40,554 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(1,Vivian,Hamilton,1971-07-08,green,1)\n",
      "(2,Karen,Holcomb,1974-05-23,green,4)\n",
      "(3,Cody,Garrett,1973-04-22,orange,1)\n",
      "(4,Roth,Fry,1975-01-29,black,1)\n",
      "(5,Zoe,Conway,1974-07-03,blue,2)\n",
      "(6,Gretchen,Kinney,1974-10-18,viole,1)\n",
      "(7,Driscoll,Klein,1970-10-05,blue,5)\n",
      "(8,Karyn,Diaz,1969-02-24,red,1)\n",
      "(9,Merritt,Guy,1974-10-17,indigo,4)\n",
      "(10,Kylan,Sexton,1975-02-28,black,4)\n",
      "(11,Jordan,Estes,1969-12-07,indigo,4)\n",
      "(12,Hope,Coffey,1973-12-24,green,5)\n",
      "(13,Vivian,Crane,1970-08-27,gray,5)\n",
      "(14,Clio,Noel,1972-12-12,red,5)\n",
      "(15,Hope,Silva,1970-07-01,blue,5)\n",
      "(16,Ayanna,Jarvis,1974-02-11,orange,5)\n",
      "(17,Chanda,Boyer,1973-04-01,green,4)\n",
      "(18,Chadwick,Knight,1973-04-29,yellow,1)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "u = LOAD 'data.csv' USING PigStorage(',') \n",
    "    AS (id:int, \n",
    "        firstname:CHARARRAY, \n",
    "        surname:CHARARRAY, \n",
    "        birthday:CHARARRAY, \n",
    "        color:CHARARRAY, \n",
    "        quantity:INT);\n",
    "DUMP u;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tabla_fecha = FOREACH u GENERATE \n",
      " ToString(ToDate(birthday, 'yyyy-MM-dd'),'yyyy-MM-dd'),\n",
      "ToString(ToDate(birthday, 'yyyy-MM-dd'),'dd'),\n",
      "ToString(ToDate(birthday, 'yyyy-MM-dd'),'d'),\n",
      "' THEN 'sab' WHEN '7' THEN 'dom' END, '4' THEN 'jue' WHEN '5' THEN 'vie' WHEN '6 \n",
      " 'viernes' WHEN '6' THEN 'sabado' WHEN '7' THEN 'domingo' END;ves' WHEN '5' THEN \n",
      " DUMP tabla_fecha;\n",
      "2020-03-07 00:01:41,608 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-07 00:01:41,865 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-07 00:01:41,893 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-03-07 00:01:41,921 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-07 00:01:41,970 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-03-07 00:01:42,028 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1583528081834_0087\n",
      "2020-03-07 00:01:42,033 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-03-07 00:01:42,082 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1583528081834_0087\n",
      "2020-03-07 00:01:42,089 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://d360b6ea3f8c:8088/proxy/application_1583528081834_0087/\n",
      "2020-03-07 00:02:02,220 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-07 00:02:02,224 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-07 00:02:02,311 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-07 00:02:02,316 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-07 00:02:02,357 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-07 00:02:02,363 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-07 00:02:02,410 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-07 00:02:02,415 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-07 00:02:02,460 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-07 00:02:02,465 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-07 00:02:02,502 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-07 00:02:02,507 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-07 00:02:02,565 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(1971-07-08,08,8,jue,jueves)\n",
      "(1974-05-23,23,23,jue,jueves)\n",
      "(1973-04-22,22,22,dom,domingo)\n",
      "(1975-01-29,29,29,mie,miercoles)\n",
      "(1974-07-03,03,3,mie,miercoles)\n",
      "(1974-10-18,18,18,vie,viernes)\n",
      "(1970-10-05,05,5,lun,lunes)\n",
      "(1969-02-24,24,24,lun,lunes)\n",
      "(1974-10-17,17,17,jue,jueves)\n",
      "(1975-02-28,28,28,vie,viernes)\n",
      "(1969-12-07,07,7,dom,domingo)\n",
      "(1973-12-24,24,24,lun,lunes)\n",
      "(1970-08-27,27,27,jue,jueves)\n",
      "(1972-12-12,12,12,mar,martes)\n",
      "(1970-07-01,01,1,mie,miercoles)\n",
      "(1974-02-11,11,11,lun,lunes)\n",
      "(1973-04-01,01,1,dom,domingo)\n",
      "(1973-04-29,29,29,dom,domingo)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "tabla_fecha = FOREACH u GENERATE \n",
    "ToString(ToDate(birthday, 'yyyy-MM-dd'),'yyyy-MM-dd'),\n",
    "ToString(ToDate(birthday, 'yyyy-MM-dd'),'dd'),\n",
    "ToString(ToDate(birthday, 'yyyy-MM-dd'),'d'),\n",
    "CASE ToString(ToDate(birthday,'yyyy-MM-dd'), 'e') WHEN '1' THEN 'lun' WHEN '2' THEN 'mar' WHEN '3' THEN 'mie' WHEN '4' THEN 'jue' WHEN '5' THEN 'vie' WHEN '6' THEN 'sab' WHEN '7' THEN 'dom' END,\n",
    "CASE ToString(ToDate(birthday,'yyyy-MM-dd'), 'e') WHEN '1' THEN 'lunes' WHEN '2' THEN 'martes' WHEN '3' THEN 'miercoles' WHEN '4' THEN 'jueves' WHEN '5' THEN 'viernes' WHEN '6' THEN 'sabado' WHEN '7' THEN 'domingo' END;\n",
    "DUMP tabla_fecha;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " STORE tabla_fecha INTO 'output' USING PigStorage(',');\n",
      "2020-03-07 00:03:25,488 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 6000: <line 15, column 0> Output Location Validation Failed for: 'hdfs://0.0.0.0:9000/user/root/output More info to follow:\n",
      "Output directory hdfs://0.0.0.0:9000/user/root/output already exists\n",
      "Details at logfile: /datalake/evaluacion-final-jorgmoga/02-pig-50/q30-10/pig_1583539257150.log\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "STORE tabla_fecha INTO 'output' USING PigStorage(',');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1971-07-08,08,8,jue,jueves\n",
      "1974-05-23,23,23,jue,jueves\n",
      "1973-04-22,22,22,dom,domingo\n",
      "1975-01-29,29,29,mie,miercoles\n",
      "1974-07-03,03,3,mie,miercoles\n",
      "1974-10-18,18,18,vie,viernes\n",
      "1970-10-05,05,5,lun,lunes\n",
      "1969-02-24,24,24,lun,lunes\n",
      "1974-10-17,17,17,jue,jueves\n",
      "1975-02-28,28,28,vie,viernes\n",
      "1969-12-07,07,7,dom,domingo\n",
      "1973-12-24,24,24,lun,lunes\n",
      "1970-08-27,27,27,jue,jueves\n",
      "1972-12-12,12,12,mar,martes\n",
      "1970-07-01,01,1,mie,miercoles\n",
      "1974-02-11,11,11,lun,lunes\n",
      "1973-04-01,01,1,dom,domingo\n",
      "1973-04-29,29,29,dom,domingo\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -cat output/part-*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   1 root supergroup        632 2020-03-07 00:01 data.csv\n",
      "drwxr-xr-x   - root supergroup          0 2020-03-07 00:03 output\n",
      "Deleted output/_SUCCESS\n",
      "Deleted output/part-m-00000\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls\n",
    "!hadoop fs -rm output/*\n",
    "!hadoop fs -rmdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rw-r--r--   1 root supergroup        632 2020-03-07 00:01 data.csv\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted data.csv\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -rm data.csv;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
