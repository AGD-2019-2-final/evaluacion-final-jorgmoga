{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted data.tsv\n",
      "Found 2 items\n",
      "-rw-r--r--   1 root supergroup       1780 2020-03-06 14:29 data.tsv\n",
      "drwxr-xr-x   - root supergroup          0 2020-03-06 14:27 output\n"
     ]
    }
   ],
   "source": [
    "%load_ext bigdata\n",
    "%pig_start\n",
    "%timeout 300\n",
    "!hadoop fs -rm data.tsv\n",
    "!hadoop fs -put data.tsv\n",
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\t{(b),(g),(f)}\t[jjj#3,bbb#0,ddd#9,ggg#8,hhh#2]\n",
      "A\t{(a),(f),(c)}\t[ccc#2,ddd#0,aaa#3,hhh#9]\n",
      "B\t{(f),(e),(a),(c)}\t[ddd#2,ggg#5,ccc#6,jjj#1]\n",
      "A\t{(a),(b)}\t[hhh#9,iii#5,eee#7,bbb#1]\n",
      "C\t{(f),(g),(d),(a)}\t[iii#6,ddd#5,eee#4,jjj#3]\n",
      "A\t{(c),(d)}\t[bbb#2,hhh#0,ccc#4,fff#1,aaa#7]\n",
      "A\t{(g),(d),(a)}\t[aaa#5,fff#8,ddd#2,iii#0,jjj#7,ccc#1]\n",
      "B\t{(b),(a)}\t[fff#3,hhh#1,ddd#2]\n",
      "E\t{(d),(e),(a),(f)}\t[eee#4,ccc#5,iii#9,fff#7,ggg#6,bbb#0]\n",
      "B\t{(d),(b),(g),(f)}\t[bbb#7,jjj#9,fff#5,iii#4,ggg#2,eee#3]\n",
      "C\t{(d),(c),(f),(b)}\t[hhh#6,eee#4,iii#0,fff#2,jjj#1]\n",
      "C\t{(d),(e),(a),(c)}\t[bbb#7,iii#6,ggg#9]\n",
      "D\t{(g),(e),(f),(b)}\t[bbb#9,aaa#3,ccc#6,fff#4,eee#2]\n",
      "E\t{(c),(f)}\t[aaa#8,ddd#5,jjj#1]\n",
      "B\t{(d),(b)}\t[ccc#0,jjj#6,fff#7,ddd#3,aaa#2]\n",
      "D\t{(f),(e)}\t[ccc#0,eee#6,bbb#9,ddd#3]\n",
      "E\t{(e),(b),(f)}\t[bbb#6,iii#3,hhh#5,fff#4,ggg#9,ddd#2]\n",
      "D\t{(g),(a)}\t[hhh#4,jjj#5,ccc#9]\n",
      "E\t{(e),(c),(f),(a)}\t[ccc#1,iii#6,fff#9]\n",
      "E\t{(e),(a)}\t[bbb#9,aaa#3,fff#1]\n",
      "E\t{(e),(f)}\t[ddd#9,iii#2,aaa#4]\n",
      "E\t{(c),(b),(g)}\t[ccc#5,fff#8,iii#7]\n",
      "D\t{(c),(f),(a)}\t[eee#3,jjj#2,ddd#7]\n",
      "A\t{(f),(a),(d)}\t[jjj#1,ggg#0,ccc#7,ddd#9,bbb#3]\n",
      "E\t{(c),(d)}\t[jjj#6,ccc#0,aaa#1,hhh#9,iii#7,ggg#8]\n",
      "E\t{(e),(d),(c)}\t[fff#3,eee#6,iii#4,bbb#7,ddd#0,ccc#1]\n",
      "A\t{(a),(e),(f)}\t[fff#0,ddd#5,ccc#4]\n",
      "E\t{(c),(a),(g)}\t[ggg#6,hhh#3,ddd#9,ccc#0,jjj#7]\n",
      "A\t{(f),(e)}\t[hhh#6,jjj#0,eee#5,iii#7,ccc#3]\n",
      "C\t{(f),(c),(a),(g)}\t[eee#1,fff#4,aaa#2,ccc#7,ggg#0,ddd#6]\n",
      "A\t{(b),(f)}\t[ccc#6,aaa#9,eee#5,ddd#0,bbb#3]\n",
      "D\t{(b),(f)}\t[bbb#7,hhh#1,aaa#6,iii#4,fff#9,ddd#5]\n",
      "E\t{(a),(c)}\t[fff#3,ccc#1,ggg#2,eee#5]\n",
      "B\t{(b),(f),(c)}\t[iii#7,ggg#3,ddd#0,jjj#8,hhh#5,ccc#1]\n",
      "B\t{(f),(a),(e)}\t[hhh#6,ccc#3,jjj#0,bbb#8,ddd#7]\n",
      "D\t{(a),(f)}\t[aaa#0,fff#5,ddd#3]\n",
      "B\t{(c),(a)}\t[ddd#5,jjj#2,iii#7,ccc#0,bbb#4]\n",
      "C\t{(c),(a),(e),(f)}\t[eee#0,fff#2,hhh#6]\n",
      "E\t{(e),(d)}\t[fff#9,iii#2,eee#0]\n",
      "E\t{(f),(a),(d)}\t[hhh#8,ggg#3,jjj#5]"
     ]
    }
   ],
   "source": [
    "!hadoop fs -cat data.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lines = LOAD 'data.tsv' USING PigStorage('\\t') AS (\n",
      "letra:CHARARRAY,\n",
      "conjunto_tuplas:BAG{t: TUPLE(p:CHARARRAY)},\n",
      "parejas:MAP[]);\n",
      " DUMP lines;\n",
      "2020-03-06 14:30:09,942 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 14:30:10,377 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-03-06 14:30:10,383 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2020-03-06 14:30:10,398 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2020-03-06 14:30:11,435 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2020-03-06 14:30:11,446 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 14:30:11,490 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-03-06 14:30:11,645 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-03-06 14:30:11,687 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-06 14:30:11,817 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-03-06 14:30:12,098 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1583503056439_0029\n",
      "2020-03-06 14:30:12,332 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-03-06 14:30:12,550 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1583503056439_0029\n",
      "2020-03-06 14:30:12,601 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://5eb5f6c70dec:8088/proxy/application_1583503056439_0029/\n",
      "2020-03-06 14:30:32,662 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 14:30:32,673 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 14:30:32,907 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 14:30:32,914 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 14:30:32,955 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-03-06 14:30:32,959 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 14:30:32,965 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 14:30:33,064 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 14:30:33,070 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 14:30:33,118 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 14:30:33,123 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 14:30:33,161 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 14:30:33,167 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 14:30:33,242 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(E,{(b),(g),(f)},[hhh#2,bbb#0,jjj#3,ddd#9,ggg#8])\n",
      "(A,{(a),(f),(c)},[aaa#3,hhh#9,ccc#2,ddd#0])\n",
      "(B,{(f),(e),(a),(c)},[ccc#6,jjj#1,ddd#2,ggg#5])\n",
      "(A,{(a),(b)},[iii#5,hhh#9,bbb#1,eee#7])\n",
      "(C,{(f),(g),(d),(a)},[iii#6,jjj#3,eee#4,ddd#5])\n",
      "(A,{(c),(d)},[aaa#7,hhh#0,ccc#4,bbb#2,fff#1])\n",
      "(A,{(g),(d),(a)},[aaa#5,iii#0,ccc#1,jjj#7,ddd#2,fff#8])\n",
      "(B,{(b),(a)},[ddd#2,hhh#1,fff#3])\n",
      "(E,{(d),(e),(a),(f)},[iii#9,ccc#5,bbb#0,eee#4,ggg#6,fff#7])\n",
      "(B,{(d),(b),(g),(f)},[iii#4,bbb#7,jjj#9,eee#3,ggg#2,fff#5])\n",
      "(C,{(d),(c),(f),(b)},[iii#0,hhh#6,jjj#1,eee#4,fff#2])\n",
      "(C,{(d),(e),(a),(c)},[iii#6,ggg#9,bbb#7])\n",
      "(D,{(g),(e),(f),(b)},[aaa#3,ccc#6,bbb#9,eee#2,fff#4])\n",
      "(E,{(c),(f)},[aaa#8,ddd#5,jjj#1])\n",
      "(B,{(d),(b)},[aaa#2,ccc#0,jjj#6,ddd#3,fff#7])\n",
      "(D,{(f),(e)},[ccc#0,bbb#9,eee#6,ddd#3])\n",
      "(E,{(e),(b),(f)},[iii#3,hhh#5,bbb#6,ddd#2,ggg#9,fff#4])\n",
      "(D,{(g),(a)},[hhh#4,ccc#9,jjj#5])\n",
      "(E,{(e),(c),(f),(a)},[iii#6,ccc#1,fff#9])\n",
      "(E,{(e),(a)},[aaa#3,bbb#9,fff#1])\n",
      "(E,{(e),(f)},[aaa#4,iii#2,ddd#9])\n",
      "(E,{(c),(b),(g)},[iii#7,ccc#5,fff#8])\n",
      "(D,{(c),(f),(a)},[eee#3,ddd#7,jjj#2])\n",
      "(A,{(f),(a),(d)},[ccc#7,bbb#3,jjj#1,ddd#9,ggg#0])\n",
      "(E,{(c),(d)},[aaa#1,iii#7,hhh#9,ccc#0,jjj#6,ggg#8])\n",
      "(E,{(e),(d),(c)},[iii#4,ccc#1,bbb#7,eee#6,ddd#0,fff#3])\n",
      "(A,{(a),(e),(f)},[ddd#5,ccc#4,fff#0])\n",
      "(E,{(c),(a),(g)},[hhh#3,ccc#0,jjj#7,ddd#9,ggg#6])\n",
      "(A,{(f),(e)},[iii#7,hhh#6,ccc#3,jjj#0,eee#5])\n",
      "(C,{(f),(c),(a),(g)},[aaa#2,ccc#7,eee#1,ddd#6,ggg#0,fff#4])\n",
      "(A,{(b),(f)},[aaa#9,ccc#6,bbb#3,eee#5,ddd#0])\n",
      "(D,{(b),(f)},[aaa#6,iii#4,hhh#1,bbb#7,ddd#5,fff#9])\n",
      "(E,{(a),(c)},[ccc#1,eee#5,ggg#2,fff#3])\n",
      "(B,{(b),(f),(c)},[iii#7,hhh#5,ccc#1,jjj#8,ddd#0,ggg#3])\n",
      "(B,{(f),(a),(e)},[hhh#6,ccc#3,bbb#8,jjj#0,ddd#7])\n",
      "(D,{(a),(f)},[aaa#0,ddd#3,fff#5])\n",
      "(B,{(c),(a)},[iii#7,ccc#0,bbb#4,jjj#2,ddd#5])\n",
      "(C,{(c),(a),(e),(f)},[eee#0,hhh#6,fff#2])\n",
      "(E,{(e),(d)},[eee#0,iii#2,fff#9])\n",
      "(E,{(f),(a),(d)},[hhh#8,ggg#3,jjj#5])\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "lines = LOAD 'data.tsv' USING PigStorage('\\t') AS (\n",
    "letra:CHARARRAY,\n",
    "conjunto_tuplas:BAG{t: TUPLE(p:CHARARRAY)},\n",
    "parejas:MAP[]);\n",
    "DUMP lines;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " letras = FOREACH lines GENERATE FLATTEN(parejas);\n",
      " DUMP letras;\n",
      "2020-03-06 14:30:33,642 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 14:30:33,870 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 14:30:33,897 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-03-06 14:30:33,918 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-06 14:30:33,978 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-03-06 14:30:34,039 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1583503056439_0030\n",
      "2020-03-06 14:30:34,046 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-03-06 14:30:34,104 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1583503056439_0030\n",
      "2020-03-06 14:30:34,109 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://5eb5f6c70dec:8088/proxy/application_1583503056439_0030/\n",
      "2020-03-06 14:30:54,701 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 14:30:54,711 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 14:30:54,811 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 14:30:54,822 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 14:30:54,882 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 14:30:54,891 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 14:30:54,945 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 14:30:54,950 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 14:30:55,017 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 14:30:55,027 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 14:30:55,073 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 14:30:55,079 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 14:30:55,149 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(bbb,0)\n",
      "(ddd,9)\n",
      "(ggg,8)\n",
      "(hhh,2)\n",
      "(jjj,3)\n",
      "(aaa,3)\n",
      "(ccc,2)\n",
      "(ddd,0)\n",
      "(hhh,9)\n",
      "(ccc,6)\n",
      "(ddd,2)\n",
      "(ggg,5)\n",
      "(jjj,1)\n",
      "(bbb,1)\n",
      "(eee,7)\n",
      "(iii,5)\n",
      "(hhh,9)\n",
      "(eee,4)\n",
      "(ddd,5)\n",
      "(iii,6)\n",
      "(jjj,3)\n",
      "(aaa,7)\n",
      "(ccc,4)\n",
      "(bbb,2)\n",
      "(fff,1)\n",
      "(hhh,0)\n",
      "(aaa,5)\n",
      "(ccc,1)\n",
      "(ddd,2)\n",
      "(fff,8)\n",
      "(iii,0)\n",
      "(jjj,7)\n",
      "(ddd,2)\n",
      "(fff,3)\n",
      "(hhh,1)\n",
      "(ccc,5)\n",
      "(bbb,0)\n",
      "(eee,4)\n",
      "(ggg,6)\n",
      "(fff,7)\n",
      "(iii,9)\n",
      "(bbb,7)\n",
      "(eee,3)\n",
      "(ggg,2)\n",
      "(fff,5)\n",
      "(iii,4)\n",
      "(jjj,9)\n",
      "(eee,4)\n",
      "(fff,2)\n",
      "(iii,0)\n",
      "(hhh,6)\n",
      "(jjj,1)\n",
      "(bbb,7)\n",
      "(ggg,9)\n",
      "(iii,6)\n",
      "(aaa,3)\n",
      "(ccc,6)\n",
      "(bbb,9)\n",
      "(eee,2)\n",
      "(fff,4)\n",
      "(aaa,8)\n",
      "(ddd,5)\n",
      "(jjj,1)\n",
      "(aaa,2)\n",
      "(ccc,0)\n",
      "(ddd,3)\n",
      "(fff,7)\n",
      "(jjj,6)\n",
      "(ccc,0)\n",
      "(bbb,9)\n",
      "(eee,6)\n",
      "(ddd,3)\n",
      "(bbb,6)\n",
      "(ddd,2)\n",
      "(ggg,9)\n",
      "(fff,4)\n",
      "(iii,3)\n",
      "(hhh,5)\n",
      "(ccc,9)\n",
      "(hhh,4)\n",
      "(jjj,5)\n",
      "(ccc,1)\n",
      "(fff,9)\n",
      "(iii,6)\n",
      "(aaa,3)\n",
      "(bbb,9)\n",
      "(fff,1)\n",
      "(aaa,4)\n",
      "(ddd,9)\n",
      "(iii,2)\n",
      "(ccc,5)\n",
      "(fff,8)\n",
      "(iii,7)\n",
      "(eee,3)\n",
      "(ddd,7)\n",
      "(jjj,2)\n",
      "(ccc,7)\n",
      "(bbb,3)\n",
      "(ddd,9)\n",
      "(ggg,0)\n",
      "(jjj,1)\n",
      "(aaa,1)\n",
      "(ccc,0)\n",
      "(ggg,8)\n",
      "(iii,7)\n",
      "(hhh,9)\n",
      "(jjj,6)\n",
      "(ccc,1)\n",
      "(bbb,7)\n",
      "(eee,6)\n",
      "(ddd,0)\n",
      "(fff,3)\n",
      "(iii,4)\n",
      "(ccc,4)\n",
      "(ddd,5)\n",
      "(fff,0)\n",
      "(ccc,0)\n",
      "(ddd,9)\n",
      "(ggg,6)\n",
      "(hhh,3)\n",
      "(jjj,7)\n",
      "(ccc,3)\n",
      "(eee,5)\n",
      "(iii,7)\n",
      "(hhh,6)\n",
      "(jjj,0)\n",
      "(aaa,2)\n",
      "(ccc,7)\n",
      "(eee,1)\n",
      "(ddd,6)\n",
      "(ggg,0)\n",
      "(fff,4)\n",
      "(aaa,9)\n",
      "(ccc,6)\n",
      "(bbb,3)\n",
      "(eee,5)\n",
      "(ddd,0)\n",
      "(aaa,6)\n",
      "(bbb,7)\n",
      "(ddd,5)\n",
      "(fff,9)\n",
      "(iii,4)\n",
      "(hhh,1)\n",
      "(ccc,1)\n",
      "(eee,5)\n",
      "(ggg,2)\n",
      "(fff,3)\n",
      "(ccc,1)\n",
      "(ddd,0)\n",
      "(ggg,3)\n",
      "(iii,7)\n",
      "(hhh,5)\n",
      "(jjj,8)\n",
      "(ccc,3)\n",
      "(bbb,8)\n",
      "(ddd,7)\n",
      "(hhh,6)\n",
      "(jjj,0)\n",
      "(aaa,0)\n",
      "(ddd,3)\n",
      "(fff,5)\n",
      "(ccc,0)\n",
      "(bbb,4)\n",
      "(ddd,5)\n",
      "(iii,7)\n",
      "(jjj,2)\n",
      "(eee,0)\n",
      "(fff,2)\n",
      "(hhh,6)\n",
      "(eee,0)\n",
      "(fff,9)\n",
      "(iii,2)\n",
      "(ggg,3)\n",
      "(hhh,8)\n",
      "(jjj,5)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "letras = FOREACH lines GENERATE FLATTEN(parejas);\n",
    "DUMP letras;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " letras1 = FOREACH letras GENERATE $0;\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "letras1 = FOREACH letras GENERATE $0;\n",
    "DUMP letras1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pig\n",
    "conteo = GROUP letras1 BY $0;\n",
    "DUMP conteo;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pig\n",
    "conteo1 = FOREACH conteo GENERATE group, COUNT($1);\n",
    "DUMP conteo1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pig\n",
    "STORE conteo1 INTO 'output' USING PigStorage(',');\n",
    "fs -get output/ .;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -cat output/part-r-*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted output/_SUCCESS\n",
      "Deleted output/part-r-00000\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -rm output/*\n",
    "!hadoop fs -rmdir output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
