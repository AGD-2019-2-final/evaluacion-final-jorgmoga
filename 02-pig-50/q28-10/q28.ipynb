{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bigdata extension is already loaded. To reload it, use:\n",
      "  %reload_ext bigdata\n",
      "rm: `data.csv': No such file or directory\n",
      "Found 1 items\n",
      "-rw-r--r--   1 root supergroup        632 2020-03-06 22:27 data.csv\n"
     ]
    }
   ],
   "source": [
    "%load_ext bigdata\n",
    "%pig_start\n",
    "%timeout 300\n",
    "!hadoop fs -rm data.csv\n",
    "!hadoop fs -put data.csv\n",
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,Vivian,Hamilton,1971-07-08,green,1\n",
      "2,Karen,Holcomb,1974-05-23,green,4\n",
      "3,Cody,Garrett,1973-04-22,orange,1\n",
      "4,Roth,Fry,1975-01-29,black,1\n",
      "5,Zoe,Conway,1974-07-03,blue,2\n",
      "6,Gretchen,Kinney,1974-10-18,viole,1\n",
      "7,Driscoll,Klein,1970-10-05,blue,5\n",
      "8,Karyn,Diaz,1969-02-24,red,1\n",
      "9,Merritt,Guy,1974-10-17,indigo,4\n",
      "10,Kylan,Sexton,1975-02-28,black,4\n",
      "11,Jordan,Estes,1969-12-07,indigo,4\n",
      "12,Hope,Coffey,1973-12-24,green,5\n",
      "13,Vivian,Crane,1970-08-27,gray,5\n",
      "14,Clio,Noel,1972-12-12,red,5\n",
      "15,Hope,Silva,1970-07-01,blue,5\n",
      "16,Ayanna,Jarvis,1974-02-11,orange,5\n",
      "17,Chanda,Boyer,1973-04-01,green,4\n",
      "18,Chadwick,Knight,1973-04-29,yellow,1"
     ]
    }
   ],
   "source": [
    "!hadoop fs -cat data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " u = LOAD 'data.csv' USING PigStorage(',') \n",
      "    AS (id:int, \n",
      "        firstname:CHARARRAY, \n",
      "        surname:CHARARRAY, \n",
      "        birthday:CHARARRAY, \n",
      "        color:CHARARRAY, \n",
      "        quantity:INT);\n",
      " DUMP u;\n",
      "2020-03-06 22:27:41,849 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:27:42,112 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-03-06 22:27:42,119 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2020-03-06 22:27:42,137 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2020-03-06 22:27:42,618 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2020-03-06 22:27:42,629 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:27:42,663 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-03-06 22:27:42,788 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-03-06 22:27:42,828 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-06 22:27:42,923 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-03-06 22:27:43,092 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1583528081834_0043\n",
      "2020-03-06 22:27:43,260 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-03-06 22:27:43,510 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1583528081834_0043\n",
      "2020-03-06 22:27:43,573 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://d360b6ea3f8c:8088/proxy/application_1583528081834_0043/\n",
      "2020-03-06 22:28:03,767 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:03,787 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 22:28:04,073 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:04,080 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 22:28:04,120 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-03-06 22:28:04,123 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:04,131 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 22:28:04,228 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:04,238 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 22:28:04,293 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:04,298 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 22:28:04,342 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:04,348 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 22:28:04,425 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(1,Vivian,Hamilton,1971-07-08,green,1)\n",
      "(2,Karen,Holcomb,1974-05-23,green,4)\n",
      "(3,Cody,Garrett,1973-04-22,orange,1)\n",
      "(4,Roth,Fry,1975-01-29,black,1)\n",
      "(5,Zoe,Conway,1974-07-03,blue,2)\n",
      "(6,Gretchen,Kinney,1974-10-18,viole,1)\n",
      "(7,Driscoll,Klein,1970-10-05,blue,5)\n",
      "(8,Karyn,Diaz,1969-02-24,red,1)\n",
      "(9,Merritt,Guy,1974-10-17,indigo,4)\n",
      "(10,Kylan,Sexton,1975-02-28,black,4)\n",
      "(11,Jordan,Estes,1969-12-07,indigo,4)\n",
      "(12,Hope,Coffey,1973-12-24,green,5)\n",
      "(13,Vivian,Crane,1970-08-27,gray,5)\n",
      "(14,Clio,Noel,1972-12-12,red,5)\n",
      "(15,Hope,Silva,1970-07-01,blue,5)\n",
      "(16,Ayanna,Jarvis,1974-02-11,orange,5)\n",
      "(17,Chanda,Boyer,1973-04-01,green,4)\n",
      "(18,Chadwick,Knight,1973-04-29,yellow,1)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "u = LOAD 'data.csv' USING PigStorage(',') \n",
    "    AS (id:int, \n",
    "        firstname:CHARARRAY, \n",
    "        surname:CHARARRAY, \n",
    "        birthday:CHARARRAY, \n",
    "        color:CHARARRAY, \n",
    "        quantity:INT);\n",
    "DUMP u;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d{2})', 1) as yyyy;GENERATE REGEX_EXTRACT(birthday, '(\\\\d{4})-(\\\\d{2})-(\\\\ \n",
      " DUMP tabla;\n",
      "2020-03-06 22:28:04,851 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:05,089 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:05,109 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-03-06 22:28:05,126 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-06 22:28:05,185 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-03-06 22:28:05,250 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1583528081834_0044\n",
      "2020-03-06 22:28:05,261 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-03-06 22:28:05,307 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1583528081834_0044\n",
      "2020-03-06 22:28:05,312 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://d360b6ea3f8c:8088/proxy/application_1583528081834_0044/\n",
      "2020-03-06 22:28:25,422 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:25,429 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 22:28:25,507 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:25,514 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 22:28:25,559 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:25,564 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 22:28:25,643 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:25,648 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 22:28:25,692 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:25,698 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 22:28:25,741 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:25,748 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 22:28:25,801 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(1971)\n",
      "(1974)\n",
      "(1973)\n",
      "(1975)\n",
      "(1974)\n",
      "(1974)\n",
      "(1970)\n",
      "(1969)\n",
      "(1974)\n",
      "(1975)\n",
      "(1969)\n",
      "(1973)\n",
      "(1970)\n",
      "(1972)\n",
      "(1970)\n",
      "(1974)\n",
      "(1973)\n",
      "(1973)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "tabla = FOREACH u GENERATE REGEX_EXTRACT(birthday, '(\\\\d{4})-(\\\\d{2})-(\\\\d{2})', 1) as yyyy;\n",
    "DUMP tabla;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tabla1 = FOREACH tabla GENERATE yyyy, SUBSTRING(yyyy, 2, 4) as yy;\n",
      " DUMP tabla1;\n",
      "2020-03-06 22:28:26,077 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:26,232 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:26,258 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-03-06 22:28:26,287 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-06 22:28:26,331 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-03-06 22:28:26,363 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1583528081834_0045\n",
      "2020-03-06 22:28:26,366 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-03-06 22:28:26,406 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1583528081834_0045\n",
      "2020-03-06 22:28:26,409 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://d360b6ea3f8c:8088/proxy/application_1583528081834_0045/\n",
      "2020-03-06 22:28:46,838 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:46,847 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 22:28:46,938 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:46,941 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 22:28:46,970 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:46,974 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 22:28:47,005 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:47,008 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 22:28:47,039 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:47,050 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 22:28:47,086 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:47,090 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 22:28:47,133 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(1971,71)\n",
      "(1974,74)\n",
      "(1973,73)\n",
      "(1975,75)\n",
      "(1974,74)\n",
      "(1974,74)\n",
      "(1970,70)\n",
      "(1969,69)\n",
      "(1974,74)\n",
      "(1975,75)\n",
      "(1969,69)\n",
      "(1973,73)\n",
      "(1970,70)\n",
      "(1972,72)\n",
      "(1970,70)\n",
      "(1974,74)\n",
      "(1973,73)\n",
      "(1973,73)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "tabla1 = FOREACH tabla GENERATE yyyy, SUBSTRING(yyyy, 2, 4) as yy;\n",
    "DUMP tabla1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " STORE tabla1 INTO 'output' USING PigStorage(',');\n",
      "2020-03-06 22:28:47,291 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-03-06 22:28:47,361 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:47,513 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:28:47,539 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-03-06 22:28:47,559 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-06 22:28:47,587 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-03-06 22:28:47,606 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1583528081834_0046\n",
      "2020-03-06 22:28:47,612 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-03-06 22:28:47,649 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1583528081834_0046\n",
      "2020-03-06 22:28:47,652 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://d360b6ea3f8c:8088/proxy/application_1583528081834_0046/\n",
      "2020-03-06 22:29:08,081 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:29:08,087 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 22:29:08,161 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:29:08,165 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 22:29:08,200 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:29:08,204 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 22:29:08,239 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:29:08,244 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 22:29:08,284 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:29:08,287 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 22:29:08,319 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 22:29:08,323 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "STORE tabla1 INTO 'output' USING PigStorage(',');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1971,71\n",
      "1974,74\n",
      "1973,73\n",
      "1975,75\n",
      "1974,74\n",
      "1974,74\n",
      "1970,70\n",
      "1969,69\n",
      "1974,74\n",
      "1975,75\n",
      "1969,69\n",
      "1973,73\n",
      "1970,70\n",
      "1972,72\n",
      "1970,70\n",
      "1974,74\n",
      "1973,73\n",
      "1973,73\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -cat output/part-*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   1 root supergroup        632 2020-03-06 22:27 data.csv\n",
      "drwxr-xr-x   - root supergroup          0 2020-03-06 22:29 output\n",
      "Deleted output/_SUCCESS\n",
      "Deleted output/part-m-00000\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls\n",
    "!hadoop fs -rm output/*\n",
    "!hadoop fs -rmdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rw-r--r--   1 root supergroup        632 2020-03-06 22:27 data.csv\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted data.csv\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -rm data.csv;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
