{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bigdata extension is already loaded. To reload it, use:\n",
      "  %reload_ext bigdata\n",
      "rm: `data.csv': No such file or directory\n",
      "Found 1 items\n",
      "-rw-r--r--   1 root supergroup        632 2020-03-06 21:37 data.csv\n"
     ]
    }
   ],
   "source": [
    "%load_ext bigdata\n",
    "%pig_start\n",
    "%timeout 300\n",
    "!hadoop fs -rm data.csv\n",
    "!hadoop fs -put data.csv\n",
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,Vivian,Hamilton,1971-07-08,green,1\n",
      "2,Karen,Holcomb,1974-05-23,green,4\n",
      "3,Cody,Garrett,1973-04-22,orange,1\n",
      "4,Roth,Fry,1975-01-29,black,1\n",
      "5,Zoe,Conway,1974-07-03,blue,2\n",
      "6,Gretchen,Kinney,1974-10-18,viole,1\n",
      "7,Driscoll,Klein,1970-10-05,blue,5\n",
      "8,Karyn,Diaz,1969-02-24,red,1\n",
      "9,Merritt,Guy,1974-10-17,indigo,4\n",
      "10,Kylan,Sexton,1975-02-28,black,4\n",
      "11,Jordan,Estes,1969-12-07,indigo,4\n",
      "12,Hope,Coffey,1973-12-24,green,5\n",
      "13,Vivian,Crane,1970-08-27,gray,5\n",
      "14,Clio,Noel,1972-12-12,red,5\n",
      "15,Hope,Silva,1970-07-01,blue,5\n",
      "16,Ayanna,Jarvis,1974-02-11,orange,5\n",
      "17,Chanda,Boyer,1973-04-01,green,4\n",
      "18,Chadwick,Knight,1973-04-29,yellow,1"
     ]
    }
   ],
   "source": [
    "!hadoop fs -cat data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " u = LOAD 'data.csv' USING PigStorage(',') \n",
      "    AS (id:int, \n",
      "        firstname:CHARARRAY, \n",
      "        surname:CHARARRAY, \n",
      "        birthday:CHARARRAY, \n",
      "        color:CHARARRAY, \n",
      "        quantity:INT);\n",
      " DUMP u;\n",
      "2020-03-06 21:38:01,908 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:38:02,223 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-03-06 21:38:02,230 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2020-03-06 21:38:02,249 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2020-03-06 21:38:02,739 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2020-03-06 21:38:02,750 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:38:02,784 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-03-06 21:38:02,913 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-03-06 21:38:02,958 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-06 21:38:03,049 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-03-06 21:38:03,671 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1583528081834_0017\n",
      "2020-03-06 21:38:03,850 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-03-06 21:38:04,041 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1583528081834_0017\n",
      "2020-03-06 21:38:04,106 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://d360b6ea3f8c:8088/proxy/application_1583528081834_0017/\n",
      "2020-03-06 21:38:24,347 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:38:24,375 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 21:38:24,688 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:38:24,697 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 21:38:24,736 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-03-06 21:38:24,739 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:38:24,745 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 21:38:24,834 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:38:24,839 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 21:38:24,885 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:38:24,894 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 21:38:24,952 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:38:24,959 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 21:38:25,053 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(1,Vivian,Hamilton,1971-07-08,green,1)\n",
      "(2,Karen,Holcomb,1974-05-23,green,4)\n",
      "(3,Cody,Garrett,1973-04-22,orange,1)\n",
      "(4,Roth,Fry,1975-01-29,black,1)\n",
      "(5,Zoe,Conway,1974-07-03,blue,2)\n",
      "(6,Gretchen,Kinney,1974-10-18,viole,1)\n",
      "(7,Driscoll,Klein,1970-10-05,blue,5)\n",
      "(8,Karyn,Diaz,1969-02-24,red,1)\n",
      "(9,Merritt,Guy,1974-10-17,indigo,4)\n",
      "(10,Kylan,Sexton,1975-02-28,black,4)\n",
      "(11,Jordan,Estes,1969-12-07,indigo,4)\n",
      "(12,Hope,Coffey,1973-12-24,green,5)\n",
      "(13,Vivian,Crane,1970-08-27,gray,5)\n",
      "(14,Clio,Noel,1972-12-12,red,5)\n",
      "(15,Hope,Silva,1970-07-01,blue,5)\n",
      "(16,Ayanna,Jarvis,1974-02-11,orange,5)\n",
      "(17,Chanda,Boyer,1973-04-01,green,4)\n",
      "(18,Chadwick,Knight,1973-04-29,yellow,1)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "u = LOAD 'data.csv' USING PigStorage(',') \n",
    "    AS (id:int, \n",
    "        firstname:CHARARRAY, \n",
    "        surname:CHARARRAY, \n",
    "        birthday:CHARARRAY, \n",
    "        color:CHARARRAY, \n",
    "        quantity:INT);\n",
    "DUMP u;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d{2})', 2);REACH u GENERATE REGEX_EXTRACT(birthday, '(\\\\d{4})-(\\\\d{2})-(\\\\ \n",
      " DUMP tabla;\n",
      "2020-03-06 21:38:25,509 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:38:25,746 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:38:25,771 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-03-06 21:38:25,796 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-06 21:38:25,868 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-03-06 21:38:25,969 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1583528081834_0018\n",
      "2020-03-06 21:38:25,976 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-03-06 21:38:26,032 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1583528081834_0018\n",
      "2020-03-06 21:38:26,041 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://d360b6ea3f8c:8088/proxy/application_1583528081834_0018/\n",
      "2020-03-06 21:38:46,386 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:38:46,395 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 21:38:46,487 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:38:46,503 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 21:38:46,556 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:38:46,565 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 21:38:46,643 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:38:46,648 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 21:38:46,687 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:38:46,692 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 21:38:46,726 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:38:46,731 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 21:38:46,786 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(07)\n",
      "(05)\n",
      "(04)\n",
      "(01)\n",
      "(07)\n",
      "(10)\n",
      "(10)\n",
      "(02)\n",
      "(10)\n",
      "(02)\n",
      "(12)\n",
      "(12)\n",
      "(08)\n",
      "(12)\n",
      "(07)\n",
      "(02)\n",
      "(04)\n",
      "(04)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "tabla = FOREACH u GENERATE REGEX_EXTRACT(birthday, '(\\\\d{4})-(\\\\d{2})-(\\\\d{2})', 2);\n",
    "DUMP tabla;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " STORE tabla INTO 'output';\n",
      "2020-03-06 21:38:46,958 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-03-06 21:38:47,036 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:38:47,207 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:38:47,238 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-03-06 21:38:47,274 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-06 21:38:47,346 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-03-06 21:38:47,374 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1583528081834_0019\n",
      "2020-03-06 21:38:47,378 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-03-06 21:38:47,426 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1583528081834_0019\n",
      "2020-03-06 21:38:47,431 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://d360b6ea3f8c:8088/proxy/application_1583528081834_0019/\n",
      "2020-03-06 21:39:07,795 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:39:07,807 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 21:39:07,896 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:39:07,903 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 21:39:07,934 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:39:07,939 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 21:39:07,977 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:39:07,982 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 21:39:08,025 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:39:08,030 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-06 21:39:08,079 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-06 21:39:08,083 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "STORE tabla INTO 'output';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07\n",
      "05\n",
      "04\n",
      "01\n",
      "07\n",
      "10\n",
      "10\n",
      "02\n",
      "10\n",
      "02\n",
      "12\n",
      "12\n",
      "08\n",
      "12\n",
      "07\n",
      "02\n",
      "04\n",
      "04\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -cat output/part-*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   1 root supergroup        632 2020-03-06 21:37 data.csv\n",
      "drwxr-xr-x   - root supergroup          0 2020-03-06 21:39 output\n",
      "Deleted output/_SUCCESS\n",
      "Deleted output/part-m-00000\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls\n",
    "!hadoop fs -rm output/*\n",
    "!hadoop fs -rmdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rw-r--r--   1 root supergroup        632 2020-03-06 21:37 data.csv\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted data.csv\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -rm data.csv;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
